{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from the compressed file\n",
    "loaded_Data = np.load('Final.npz',allow_pickle=True)\n",
    "\n",
    "# create a new DataFrame from the loaded data\n",
    "colData=pd.DataFrame(loaded_Data)\n",
    "Data = pd.DataFrame({colData[0][col]: loaded_Data[colData[0][col]] for col in range(0, len(colData))})\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple for choosing number of samples\n",
    "samples=50\n",
    "df=pd.DataFrame((Data['Device'].value_counts()>=samples).value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define an autoencoder model using TensorFlow/Keras\n",
    "def create_autoencoder(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(64, activation='relu')(input_layer)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(16, activation='relu')(encoded)\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    encoder = Model(input_layer, encoded)\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mse')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "# Function to train the autoencoder\n",
    "def train_autoencoder(X, input_dim, epochs=100, batch_size=32):\n",
    "    autoencoder, encoder = create_autoencoder(input_dim)\n",
    "    \n",
    "    # Add EarlyStopping and ModelCheckpoint callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "        ModelCheckpoint(filepath='best_autoencoder.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    autoencoder.fit(X, X, epochs=epochs, batch_size=batch_size, shuffle=False, validation_split=0.2, callbacks=callbacks)\n",
    "    # Load the best model\n",
    "    autoencoder.load_weights('best_autoencoder.keras')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "array_EER = []\n",
    "device = pd.DataFrame(Data['Device'].unique())\n",
    "Train = pd.DataFrame(columns=['HTL','VTL','Slope','MSE','MAE','MedAE','CoD','HA','VA','HMP','VMP',\n",
    "                              'Device'])\n",
    "Test = pd.DataFrame(columns=['HTL','VTL','Slope','MSE','MAE','MedAE','CoD','HA','VA','HMP','VMP',\n",
    "                             'Device'])\n",
    "\n",
    "for i in range(len(device)):\n",
    "    total = len(Data[Data['Device'] == device[0][i]])\n",
    "    if(total>=10):\n",
    "        dfTrain = Data[Data['Device'] == device[0][i]].head(int(total-total*0.1))\n",
    "        dfTest = Data[Data['Device'] == device[0][i]].iloc[int(total-total*0.1):total]\n",
    "        Train = pd.concat([Train, dfTrain], ignore_index=True)\n",
    "        Test = pd.concat([Test, dfTest], ignore_index=True)\n",
    "devices=Train['Device'].unique()\n",
    "\n",
    "# Pre-train the autoencoder on the entire training data\n",
    "train_data = Train.drop('Device', axis=1).values\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "input_dim = train_data.shape[1]\n",
    "\n",
    "autoencoder, encoder = train_autoencoder(train_data, input_dim, epochs=50)\n",
    "\n",
    "for device in devices:\n",
    "    # Train\n",
    "    X_Train = Train[Train['Device'] == device]\n",
    "    X_Train = X_Train.drop('Device', axis=1)\n",
    "    X_train = scaler.transform(X_Train)\n",
    "    X_train_encoded = encoder.predict(X_train)\n",
    "    X_train_decoded = autoencoder.predict(X_train)\n",
    "\n",
    "    # Test\n",
    "    X_Test = Test[Test['Device'] == device]\n",
    "    X_Test = X_Test.drop('Device', axis=1)\n",
    "    X_test = scaler.transform(X_Test)\n",
    "    X_test_encoded = encoder.predict(X_test)\n",
    "    X_test_decoded = autoencoder.predict(X_test)\n",
    "\n",
    "    # Imposter\n",
    "    X_Imposter = pd.DataFrame(columns=['HTL','VTL','Slope','MSE','MAE','MedAE','CoD','HA','VA','HMP',\n",
    "                                       'VMP','Device'])\n",
    "    for device_imposter in devices:\n",
    "        if device_imposter != device:\n",
    "            X_Imposter = pd.concat([X_Imposter, Test[Test['Device'] == device_imposter]],\n",
    "                                   ignore_index=True)\n",
    "    X_Imposter = X_Imposter.drop('Device', axis=1)\n",
    "    X_imposter = scaler.transform(X_Imposter)\n",
    "    X_imposter_encoded = encoder.predict(X_imposter)\n",
    "    X_imposter_decoded = autoencoder.predict(X_imposter)\n",
    "\n",
    "    # Calculate reconstruction errors\n",
    "    reconstruction_error_test = np.mean(np.square(X_test - X_test_decoded), axis=1)\n",
    "    reconstruction_error_imposter = np.mean(np.square(X_imposter - X_imposter_decoded), axis=1)\n",
    "\n",
    "    # Sweep through a range of threshold values\n",
    "    mn = min(reconstruction_error_test)\n",
    "    mx = max(reconstruction_error_test)\n",
    "    thresholds = np.linspace(mn, mx, 100)  # Use np.linspace to avoid creating too large an array\n",
    "    FAR = np.zeros_like(thresholds)\n",
    "    FRR = np.zeros_like(thresholds)\n",
    "    pos = 0\n",
    "    EER = 0\n",
    "    i = 0\n",
    "    cl = 30\n",
    "    distance = len(reconstruction_error_test) + len(reconstruction_error_imposter)\n",
    "    for threshold in thresholds:\n",
    "        # Create a binary array indicating whether each data point is an anomaly or not\n",
    "        y_predI = np.where(reconstruction_error_imposter > threshold, -1, 1)\n",
    "        y_predO = np.where(reconstruction_error_test > threshold, -1, 1)\n",
    "        \n",
    "        FAR[i] = len(y_predI[y_predI == 1]) / len(reconstruction_error_imposter)\n",
    "        FRR[i] = len(y_predO[y_predO == -1]) / len(reconstruction_error_test)\n",
    "        if abs(FAR[i] - FRR[i]) < distance:\n",
    "            distance = abs(FAR[i] - FRR[i])\n",
    "            pos = threshold\n",
    "            EER = (FRR[i] + FAR[i]) / 2\n",
    "            array_EER.append(round(EER * 100, 2))\n",
    "        i += 1\n",
    "    \n",
    "    print('EER :', EER * 100)\n",
    "    # Plot the FAR and FRR curves\n",
    "    plt.plot(thresholds, FAR, label='FAR')\n",
    "    plt.plot(thresholds, FRR, label='FRR')\n",
    "    plt.plot(pos, EER, 'ro', label='EER')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Error rate')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(FAR, 1 - np.array(FRR))\n",
    "    plt.xlabel('False Acceptance Rate (FAR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
